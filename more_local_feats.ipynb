{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import vgg16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import csv\n",
    "import nmslib\n",
    "from os import path\n",
    "\n",
    "feature_dimenstion = 512 \n",
    "default_tile_size = 224\n",
    "default_neighbor_count = 3\n",
    "\n",
    "def prepare_image_paths_labels():\n",
    "    labels_file = \"household_images/labels.csv\"\n",
    "    data = genfromtxt(labels_file, delimiter=',')\n",
    "    return data\n",
    "\n",
    "\n",
    "def prepare_image_paths_labels():\n",
    "    directory_path = \"household_images/images\"\n",
    "    labels_file = \"household_images/labels.csv\"\n",
    "\n",
    "    with open(labels_file, \"rt\", encoding=\"utf8\") as f_input:\n",
    "        csv_input = csv.reader(f_input)\n",
    "        header = next(csv_input)\n",
    "        data = [row for row in csv_input]\n",
    "    \n",
    "    image_paths = [path.join(directory_path, row[0]) for row in data]\n",
    "    image_labels = [int(row[1]) for row in data]\n",
    "    \n",
    "    return image_paths, image_labels\n",
    "\n",
    "def open_and_prepare_image(image_path, window_size = 224, stride=32, steps=(15,15)):\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    target_height = window_size + (steps[0]-1) * stride\n",
    "    target_width = window_size + (steps[1]-1) * stride \n",
    "    \n",
    "    target_wh_ratio = target_width/target_height\n",
    "    \n",
    "    image_height = image.shape[0]\n",
    "    image_width = image.shape[1]\n",
    "    \n",
    "    image_wh_ratio = image_width/image_height\n",
    "    \n",
    "    # if image is taller and skinner than target, scale width first then crop height\n",
    "    # else if image is shorter and fatter than target, scale height first then crop width\n",
    "    \n",
    "    if image_wh_ratio < target_wh_ratio:\n",
    "        scale_percent = target_width/image.shape[1]\n",
    "        scale_height = math.floor(scale_percent * image.shape[0])\n",
    "        image = cv2.resize(image, (target_width, scale_height), interpolation=cv2.INTER_CUBIC)\n",
    "        m1 = (scale_height - target_height)//2\n",
    "        m2 = target_height + m1\n",
    "        return image[m1:m2,:,:]\n",
    "    \n",
    "    else:\n",
    "        scale_percent = target_height/image.shape[0]\n",
    "        scale_width = math.floor(scale_percent * image.shape[1])\n",
    "        image = cv2.resize(image, (scale_width, target_height), interpolation=cv2.INTER_CUBIC)\n",
    "        m1 = (scale_width-target_width)//2\n",
    "        m2 = target_width + m1\n",
    "        return image[:,m1:m2,:]\n",
    "\n",
    "def extract_windows(image_path, window_size = 224, stride=32, steps=(15,15)):\n",
    "    \n",
    "    image = open_and_prepare_image(image_path, window_size, stride, steps)\n",
    "    \n",
    "    print(\"image.shape\", image.shape)\n",
    "    \n",
    "    windows = np.zeros((steps[0] * steps[1], window_size, window_size, image.shape[2]))\n",
    "    coords = np.zeros((steps[0] * steps[1], 2))\n",
    "        \n",
    "    for i in range(steps[0]):\n",
    "        for j in range(steps[1]):\n",
    "            # print((stride*i),(stride*i+window_size), (stride*j),(stride*j+window_size))\n",
    "            img = image[(stride*i):(stride*i+window_size), (stride*j):(stride*j+window_size)]\n",
    "            windows[i * steps[1] + j] = img\n",
    "            coords[i * steps[1] + j] = (i, j)\n",
    "\n",
    "    return windows, coords\n",
    "\n",
    "\n",
    "def mean_local_feats(local_feats):\n",
    "\n",
    "    mean_feat = np.zeros((local_feats[0].shape[0],))\n",
    "\n",
    "    for i in range(len(local_feats)):\n",
    "        patch_feat = local_feats[i]\n",
    "        mean_feat = mean_feat + patch_feat\n",
    "\n",
    "    mean_feat = mean_feat / len(local_feats)\n",
    "\n",
    "    return mean_feat\n",
    "\n",
    "\n",
    "def calc_image_descriptors(image_path, model, window_size_blocks = 7, block_size=32, block_grid=(21,28)):\n",
    "    window_size = window_size_blocks * block_size\n",
    "    steps = (block_grid[0]-window_size_blocks+1, block_grid[1]-window_size_blocks+1)\n",
    "    stride = block_size\n",
    "    \n",
    "    windows, coords = extract_windows(image_path, window_size, stride, steps)\n",
    "\n",
    "    print(windows.shape)\n",
    "    x = preprocess_input(windows)\n",
    "    y = model.predict(x)\n",
    "    print(y.shape)\n",
    "\n",
    "    foo = {}\n",
    "    \n",
    "    for i in range(block_grid[0]):\n",
    "        for j in range(block_grid[1]):\n",
    "            foo[(i,j)] = []\n",
    "\n",
    "    for i in range(y.shape[0]):\n",
    "        coord = coords[i]\n",
    "        for j in range(y.shape[1]):\n",
    "            for k in range(y.shape[2]):\n",
    "                foo[(int(coord[0] + j), int(coord[1] + k))].append(y[i,j,k,:])\n",
    "\n",
    "    descriptors = []\n",
    "\n",
    "    window_blocks = window_size_blocks**2\n",
    "    \n",
    "    for i in range(block_grid[0]):\n",
    "        for j in range(block_grid[1]):\n",
    "            # if len(foo[(i,j)]) == window_blocks:\n",
    "            descriptors.append(mean_local_feats(foo[(i,j)]))\n",
    "    \n",
    "    return descriptors\n",
    "\n",
    "\n",
    "def main():\n",
    "    model = vgg16.VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    image_paths, image_labels = prepare_image_paths_labels()\n",
    "    \n",
    "    image_count = len(image_paths)\n",
    "    neighbor_count = default_neighbor_count\n",
    "    \n",
    "    descriptors = []\n",
    "    labels = []\n",
    "    indexes = []\n",
    "    \n",
    "    window_count = 0\n",
    "    \n",
    "    for i in range(image_count):\n",
    "    \n",
    "        image_path = image_paths[i]\n",
    "        print(i, image_path)\n",
    "    \n",
    "        image_descriptors = calc_image_descriptors(image_path, model)\n",
    "        window_count = len(image_descriptors)\n",
    "        print(\"window_count\", window_count)\n",
    "        \n",
    "        for j in range(len(image_descriptors)):\n",
    "            descriptors.append(image_descriptors[j])\n",
    "            labels.append(image_labels[i])\n",
    "            indexes.append(i)\n",
    "    \n",
    "    \n",
    "    scores = []\n",
    "            \n",
    "    desc_index = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "    desc_index.addDataPointBatch(np.array(descriptors), np.arange(len(descriptors)))\n",
    "    desc_index.createIndex({'post': 2}, print_progress=True)\n",
    "\n",
    "    for i in range(len(descriptors)):\n",
    "        descriptor = descriptors[i]\n",
    "\n",
    "        idxs, distances = desc_index.knnQuery(descriptor, k=neighbor_count + window_count)\n",
    "\n",
    "        count = 0\n",
    "        candidates = 0\n",
    "\n",
    "        for j in range(idxs.shape[0]):\n",
    "            idx = idxs[j]\n",
    "\n",
    "            if indexes[i] == indexes[idx]:\n",
    "                continue\n",
    "\n",
    "            candidates += 1\n",
    "\n",
    "            if labels[i] == labels[idx]:\n",
    "                count += 1\n",
    "\n",
    "            if candidates >= neighbor_count:\n",
    "                break\n",
    "\n",
    "            scores.append(count/candidates)\n",
    "\n",
    "    return sum(scores)/len(scores)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows, coords = extract_windows(\"household_images/images/IMG_0175.jpg\", steps=(15, 14))\n",
    "windows.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.461470852751206\n",
    "without cropping: 0.46140807316304006\n",
    "with padding: 0.44942283282143464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "windows, coords = extract_windows(\"household_images/images/IMG_0175.jpg\", steps=(1, 2))\n",
    "print(windows.shape)\n",
    "img2 = windows[1][:,:,::-1]/255\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "window_size_blocks = 7\n",
    "block_size=32\n",
    "block_grid=(21,28)\n",
    "window_size = window_size_blocks * block_size\n",
    "steps = (block_grid[0]-window_size_blocks+1, block_grid[1]-window_size_blocks+1)\n",
    "stride = block_size\n",
    "img = open_and_prepare_image(\"household_images/images/IMG_0175.jpg\", window_size = window_size, stride=stride, steps=steps)\n",
    "img2 = img[:,:,::-1]\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
