{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnswlib\n",
    "from os import listdir, path\n",
    "import numpy as np\n",
    "from keras.applications import mobilenetv2\n",
    "\n",
    "images_directory = \"household_images/images\"\n",
    "\n",
    "desc_index = hnswlib.Index(space='cosine', dim=1280)\n",
    "desc_index.init_index(max_elements=7000000, ef_construction=500, M=32)\n",
    "desc_index.set_ef(500)\n",
    "\n",
    "feature_net = mobilenetv2.MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "\n",
    "def prepare_image_paths_labels():\n",
    "    labels_file = \"household_images/labels.csv\"\n",
    "    data = genfromtxt(labels_file, delimiter=',')\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_image_paths_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def prepare_image_paths_labels():\n",
    "    labels_file = \"household_images/labels.csv\"\n",
    "\n",
    "    with open(labels_file, \"rt\", encoding=\"utf8\") as f_input:\n",
    "        csv_input = csv.reader(f_input)\n",
    "        header = next(csv_input)\n",
    "        data = [row for row in csv_input]\n",
    "    \n",
    "    image_paths = [row[0] for row in data]\n",
    "    image_labels = [int(row[1]) for row in data]\n",
    "    \n",
    "    return image_paths, image_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_image_paths_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "\n",
    "def open_and_prepare_image(image_path, tile_size = 224, vertical_tiles = 1):\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    target_height = tile_size * vertical_tiles\n",
    "    scale_percent = target_height/image.shape[0]\n",
    "    \n",
    "    horizontal_tiles = image.shape[1] * scale_percent // tile_size\n",
    "    target_width = tile_size * horizontal_tiles\n",
    "    \n",
    "    scale_width = math.floor(scale_percent * image.shape[1])\n",
    "    \n",
    "    print(\"(scale_width, target_height)\", (scale_width, target_height))\n",
    "    image = cv2.resize(image, (scale_width, target_height), interpolation=cv2.INTER_CUBIC)\n",
    "    return image\n",
    "\n",
    "\n",
    "def extract_windows(image, window_size=224, channel_count=3, interior_w=False, interior_h=False):\n",
    "    \n",
    "    n_cells = (image.shape[0] // window_size, image.shape[1] // window_size)\n",
    "\n",
    "    if interior_w:\n",
    "        n_cells = (n_cells[0] - 1, n_cells[1])\n",
    "\n",
    "    if interior_h:\n",
    "        n_cells = (n_cells[0], n_cells[1] - 1)\n",
    "\n",
    "    img_shape = (n_cells[0] * window_size, n_cells[1] * window_size)\n",
    "\n",
    "    margins = ((image.shape[0] - img_shape[0])//2, (image.shape[1] - img_shape[1])//2)\n",
    "\n",
    "    windows = np.zeros((n_cells[0] * n_cells[1], window_size, window_size, channel_count))\n",
    "    coords = np.zeros((n_cells[0] * n_cells[1], 2))\n",
    "\n",
    "    for i in range(n_cells[0]):\n",
    "        for j in range(n_cells[1]):\n",
    "            img = image[(margins[0] + window_size*i):(margins[0] + window_size*(i+1)), (margins[1] + window_size*j):(margins[1] + window_size*(j+1))]\n",
    "            windows[i * n_cells[1] + j] = img\n",
    "            coords[i * n_cells[1] + j] = (margins[0] + window_size*i + window_size//2, margins[1] + window_size*j + window_size//2)\n",
    "\n",
    "    return windows, coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "img = open_and_prepare_image(\"household_images/images/IMG_0175.jpg\")\n",
    "img2 = img[:,:,::-1]\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "res = extract_windows(img)\n",
    "windows = res[0]\n",
    "windows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = windows[0][:,:,::-1]/255\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import csv\n",
    "import hnswlib\n",
    "from os import path\n",
    "import numpy as np\n",
    "\n",
    "# InceptionResNetV2: 1536\n",
    "# DenseNet121: 1024\n",
    "# Xception 2048\n",
    "# ResNet50 2048\n",
    "# InceptionV3\n",
    "# VGG16 512\n",
    "# VGG19 512\n",
    "# MobileNet\n",
    "# MobileNetV2\n",
    "# NASNet: 4032\n",
    "\n",
    "######################################################\n",
    "from keras.applications import vgg16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "feature_dimenstion = 512 \n",
    "default_tile_size = 224\n",
    "default_vertical_tiles = 1\n",
    "default_neighbor_count = 3\n",
    "######################################################\n",
    "\n",
    "def prepare_image_paths_labels():\n",
    "    labels_file = \"household_images/labels.csv\"\n",
    "    data = genfromtxt(labels_file, delimiter=',')\n",
    "    return data\n",
    "\n",
    "\n",
    "def prepare_image_paths_labels():\n",
    "    directory_path = \"household_images/images\"\n",
    "    labels_file = \"household_images/labels.csv\"\n",
    "\n",
    "    with open(labels_file, \"rt\", encoding=\"utf8\") as f_input:\n",
    "        csv_input = csv.reader(f_input)\n",
    "        header = next(csv_input)\n",
    "        data = [row for row in csv_input]\n",
    "    \n",
    "    image_paths = [path.join(directory_path, row[0]) for row in data]\n",
    "    image_labels = [int(row[1]) for row in data]\n",
    "    \n",
    "    return image_paths, image_labels\n",
    "\n",
    "\n",
    "def open_and_prepare_image(image_path, tile_size = default_tile_size, vertical_tiles = default_vertical_tiles):\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    target_height = tile_size * vertical_tiles\n",
    "    scale_percent = target_height/image.shape[0]\n",
    "    \n",
    "    horizontal_tiles = image.shape[1] * scale_percent // tile_size\n",
    "    target_width = tile_size * horizontal_tiles\n",
    "    \n",
    "    scale_width = math.floor(scale_percent * image.shape[1])\n",
    "    \n",
    "    #print(\"(scale_width, target_height)\", (scale_width, target_height))\n",
    "    image = cv2.resize(image, (scale_width, target_height), interpolation=cv2.INTER_CUBIC)\n",
    "    return image\n",
    "\n",
    "\n",
    "def extract_windows(image, window_size=default_tile_size, channel_count=3, interior_w=False, interior_h=False):\n",
    "    \n",
    "    n_cells = (image.shape[0] // window_size, image.shape[1] // window_size)\n",
    "\n",
    "    if interior_w:\n",
    "        n_cells = (n_cells[0] - 1, n_cells[1])\n",
    "\n",
    "    if interior_h:\n",
    "        n_cells = (n_cells[0], n_cells[1] - 1)\n",
    "\n",
    "    img_shape = (n_cells[0] * window_size, n_cells[1] * window_size)\n",
    "\n",
    "    margins = ((image.shape[0] - img_shape[0])//2, (image.shape[1] - img_shape[1])//2)\n",
    "\n",
    "    windows = np.zeros((n_cells[0] * n_cells[1], window_size, window_size, channel_count))\n",
    "    coords = np.zeros((n_cells[0] * n_cells[1], 2))\n",
    "\n",
    "    for i in range(n_cells[0]):\n",
    "        for j in range(n_cells[1]):\n",
    "            img = image[(margins[0] + window_size*i):(margins[0] + window_size*(i+1)), (margins[1] + window_size*j):(margins[1] + window_size*(j+1))]\n",
    "            windows[i * n_cells[1] + j] = img\n",
    "            coords[i * n_cells[1] + j] = (margins[0] + window_size*i + window_size//2, margins[1] + window_size*j + window_size//2)\n",
    "\n",
    "    return windows, coords\n",
    "\n",
    "def convert_output(feats):\n",
    "    print(\"feats.shape\", feats.shape)\n",
    "    \n",
    "    reduced_feats = np.zeros((feats.shape[0], feats.shape[3]))\n",
    "\n",
    "    for i in range(feats.shape[0]):\n",
    "\n",
    "        patch_feats = feats[i] # 3x3x1280\n",
    "\n",
    "        tot = np.zeros((patch_feats.shape[2],))\n",
    "\n",
    "        for j in range(patch_feats.shape[0]):\n",
    "            for k in range(patch_feats.shape[1]):\n",
    "                tot = tot + patch_feats[j, k]\n",
    "\n",
    "        avg = tot / (patch_feats.shape[0] * patch_feats.shape[1])\n",
    "\n",
    "        reduced_feats[i] = avg\n",
    "\n",
    "    return reduced_feats\n",
    "\n",
    "def main():\n",
    "    \n",
    "    ######################################################\n",
    "    model = vgg16.VGG16(weights=\"imagenet\", include_top=False, input_shape=(default_tile_size, default_tile_size, 3))\n",
    "    ######################################################\n",
    "    \n",
    "    image_paths, image_labels = prepare_image_paths_labels()\n",
    "    \n",
    "    image_count = len(image_paths)\n",
    "    neighbor_count = default_neighbor_count\n",
    "    \n",
    "    descriptors = []\n",
    "    labels = []\n",
    "    indexes = []\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    window_count = 0\n",
    "    \n",
    "    \n",
    "    for i in range(image_count):\n",
    "    \n",
    "        image_path = image_paths[i]\n",
    "        print(i, image_path)\n",
    "    \n",
    "        image = open_and_prepare_image(image_path)\n",
    "        windows, coords = extract_windows(image)\n",
    "\n",
    "        window_count = windows.shape[0]\n",
    "\n",
    "        print(\"window_count\", window_count)\n",
    "    \n",
    "        batch = np.zeros((window_count, default_tile_size, default_tile_size, 3))\n",
    "\n",
    "        for j in range(window_count):\n",
    "            batch[j] = windows[j]\n",
    "\n",
    "        x = preprocess_input(batch)\n",
    "        y = model.predict(x)\n",
    "        feature = convert_output(y)\n",
    "\n",
    "        #print(\"feature.shape\", feature.shape)\n",
    "        \n",
    "        for j in range(window_count):\n",
    "            descriptors.append(feature[j, :])\n",
    "            labels.append(image_labels[i])\n",
    "            indexes.append(i)\n",
    "            \n",
    "    desc_index = hnswlib.Index(space='cosine', dim=feature_dimenstion)\n",
    "    desc_index.init_index(max_elements=1000000, ef_construction=500, M=32)\n",
    "    desc_index.set_ef(500)    \n",
    "    desc_index.add_items(np.array(descriptors), np.arange(len(descriptors)))\n",
    "    \n",
    "    \n",
    "    for i in range(len(descriptors)):\n",
    "        descriptor = descriptors[i]\n",
    "        #print(\"descriptor.shape\", descriptor.shape)\n",
    "        \n",
    "        idxs, distances = desc_index.knn_query(descriptor, k=neighbor_count + window_count)\n",
    "        #print(\"idxs.shape\", idxs.shape)\n",
    "        #print(\"distances.shape\", distances.shape)\n",
    "        \n",
    "        count = 0\n",
    "        candidates = 0\n",
    "        \n",
    "        for j in range(len(idxs[0])):\n",
    "            idx = idxs[0][j]\n",
    "            #print(\"idx\", idx)\n",
    "            \n",
    "            if indexes[i] == indexes[idx]:\n",
    "                continue\n",
    "                \n",
    "            candidates += 1\n",
    "            \n",
    "            if labels[i] == labels[idx]:\n",
    "                count += 1\n",
    "                \n",
    "            if candidates >= neighbor_count:\n",
    "                break\n",
    "        \n",
    "        #print(\"Score\", count/candidates)\n",
    "        scores.append(count/candidates)\n",
    "    \n",
    "    return sum(scores)/len(scores)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50\n",
    "\n",
    "#### 1 Tile, Cosine\n",
    "0.7532008830022079\n",
    "\n",
    "#### 1 Tile, Cosine, 7 nearest neighbors\n",
    "0.6365184484389776\n",
    "\n",
    "#### 4 Tile, Cosine\n",
    "0.6441501103752777\n",
    "\n",
    "#### 12 Tile, Cosine\n",
    "0.5460632818248746\n",
    "\n",
    "#### 20 Tile, Cosine\n",
    "0.5170860927152365\n",
    "\n",
    "#### 30 Tile, Cosine\n",
    "0.4913612950699003\n",
    "\n",
    "#### 48 Tile, Cosine\n",
    "0.4563097866078034\n",
    "\n",
    "#### 63 Tile, Cosine\n",
    "0.43885209713025397\n",
    "\n",
    "#### 1 Tile, 7x7 local feats, Cosine\n",
    "0.46622516556291393\n",
    "\n",
    "#### 4 Tile, 14x14 local feats, Cosine\n",
    "0.33907284768212403\n",
    "\n",
    "\n",
    "# VGG16\n",
    "\n",
    "### 1 Tile, Cosine\n",
    "0.7479028697571752\n",
    "\n",
    "### 1 Tile, Euclidian\n",
    "0.6693156732891836\n",
    "\n",
    "#### 1 Tile, Cosine, 7 nearest neighbors\n",
    "0.6285714285714273\n",
    "\n",
    "#### 4 Tile, Cosine\n",
    "0.6324503311258295\n",
    "\n",
    "#### 12 Tile, Cosine\n",
    "0.5251287711552626\n",
    "\n",
    "#### 1 Tile, 7x7 local feats, Cosine\n",
    "0.43178807947019865\n",
    "\n",
    "#### 12 Tile, 7x7 local feats, Cosine\n",
    "0.3110097460616839\n",
    "\n",
    "#### 3x4 Tile, 7x7 local feats, overlaping with padding Cosine\n",
    "0.44942283282143464\n",
    "\n",
    "\n",
    "# NASNet\n",
    "\n",
    "### 1 Tile, Cosine\n",
    "0.7434878587196473\n",
    "\n",
    "\n",
    "# DenseNet\n",
    "\n",
    "### 1 Tile, Cosine\n",
    "0.7434878587196473\n",
    "\n",
    "### 20 Tiles, Cosine\n",
    "0.49942604856512457\n",
    "\n",
    "\n",
    "# InceptionResNetV2\n",
    "\n",
    "### 1 Tile, Cosine\n",
    "0.7037527593818991\n",
    "\n",
    "\n",
    "# Xception\n",
    "\n",
    "### 1 Tile, Cosine\n",
    "0.7302428256070645\n",
    "\n",
    "### 1 Tile, Cosine, non optimal tile size\n",
    "0.6750551876379697\n",
    "\n",
    "# InceptionV3\n",
    "\n",
    "### 1 Tile, Cosine\n",
    "0.702428256070641\n",
    "\n",
    "### 1 Tile, Cosine, non optimal tile size\n",
    "0.6066225165562928\n",
    "\n",
    "# VGG19\n",
    "\n",
    "### 1 Tile, Cosine\n",
    "0.7359823399558499\n",
    "\n",
    "\n",
    "# MobileNetv2\n",
    "\n",
    "### 1 Tile, Cosine, input not preprocessed\n",
    "0.6838852097130254\n",
    "\n",
    "### 1 Tile, Cosine\n",
    "0.7249448123620316\n",
    "\n",
    "### 1 Tile, Euclidian, input not preprocessed\n",
    "0.6569536423841069\n",
    "\n",
    "### 4 Tiles, Cosine, input not preprocessed\n",
    "0.5366445916114811\n",
    "\n",
    "### 4 Tiles, Cosine\n",
    "0.5793598233995606\n",
    "\n",
    "### 12 Tiles, Cosine, input not preprocessed\n",
    "0.41662987490802034\n",
    "\n",
    "### 63 Tiles, Cosine, input not preprocessed\n",
    "0.28294614387331396"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import densenet\n",
    "default_tile_size = 224\n",
    "model = densenet.DenseNet201(weights=\"imagenet\", include_top=False, input_shape=(default_tile_size, default_tile_size, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
